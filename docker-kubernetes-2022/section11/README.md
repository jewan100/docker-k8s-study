# Kubernetes

> 컨테이너화된 애플리케이션의 배포, 확장, 복구, 구성을 자동화하기 위한 컨테이너 오케스트레이션 플랫폼

여러 컨테이너를 어디서 어떻게 띄울지, 몇 개를 유지할지, 트래픽을 어떻게 나눌지를 자동으로 관리하기 위한 시스템

## 컨테이너 배포의 문제점

> 컨테이너 개수가 많아질수록 사람이 직접 관리하기에는 너무 복잡해지는 구조

- 컨테이너 장애 대응 문제

  - 컨테이너 프로세스 충돌, OOM, 노드 다운 발생
  - 관리자가 직접 로그 확인 후 재시작 필요
  - 장애 감지, 재시작이 자동화되어 있지 않음

- 변경 및 배포 문제

  - 새 버전 이미지로 교체할 때 기존 컨테이너를 언제 내릴지, 새 컨테이너를 몇 개 띄울지 조율 필요
  - 잘못하면 전체 컨테이너 다운타임 발생 가능성

- 스케일 문제

  - 트래픽 급증 시 컨테이너 인스턴스를 늘려야 하는 상황
  - 일반적으로 스케일 아웃(가로 확장) 개념

    - 동일 이미지를 기반으로 여러 컨테이너 인스턴스를 생성

  - 늘어난 인스턴스들에 대해 트래픽 분산(로드 밸런싱) 필요
  - 컨테이너 개수 조절, 로드 밸런서 설정 변경을 사람이 직접 하기에는 부담이 큼

- 모니터링 및 헬스 체크 문제

  - 컨테이너 상태를 지속적으로 감시하고, 비정상 상태 시 재시작하는 로직 필요
  - 모든 것을 수동 운영이나 스크립트로 해결하기에는 한계 존재

## 클라우드 프로바이더 종속 문제

> 각 클라우드가 제공하는 자체 컨테이너 서비스에만 의존할 때의 이슈

- 예시: AWS ECS

  - 오토스케일링, 로드 밸런싱, 서비스 디스커버리 등 제공

- 문제점

  - 특정 클라우드 벤더의 API, 개념, 콘솔 UI에 강하게 종속
  - 다른 클라우드(Azure, GCP) 또는 온프레미스로 이전 시 아키텍처, 스크립트, IaC를 상당 부분 재작성해야 함
  - 멀티 클라우드, 하이브리드 환경 구성 시 유연성이 떨어짐

> [!NOTE]
> Kubernetes는 어떤 인프라 위에 올려도 동작하는 공통 추상화 계층 제공을 목표로 함

## Kubernetes란 무엇인가

> 컨테이너 오케스트레이션을 위한 오픈 소스 표준 플랫폼

- 자동 배포

  - 선언적 설정(YAML) 기반으로 원하는 상태(desired state)를 정의
  - 실제 상태를 계속 감시하면서 원하는 상태와 다르면 자동으로 조정하는 컨트롤 루프 구조

- 자동 스케일링

  - 동일한 애플리케이션 인스턴스(Pod) 개수 조절 기능
  - 수동 스케일 아웃, 자동 스케일 아웃(HPA) 모두 가능

- 로드 밸런싱 및 서비스 디스커버리

  - 여러 Pod 앞단에 Service라는 논리적인 엔드포인트 제공
  - Service가 여러 Pod로 트래픽 분산, DNS 이름 제공

- 컨테이너 관리 추상화

  - 온프레, AWS, GCP, Azure 등 어떤 호스트 머신 위에서도 동일한 방식으로 배포 가능
  - 인프라 세부 API 대신 Kubernetes API만 신경 쓰면 되는 구조

## 기본 개념 및 아키텍처

### Cluster

- Kubernetes가 관리하는 전체 단위
- 하나의 클러스터는

  - Control Plane(예전 Master Node)
  - Worker Node(워커 노드)
    로 구성

### Worker Node

> 컨테이너(Pod)가 실제로 돌아가는 물리/가상 머신

- 역할

  - 애플리케이션 컨테이너 실행
  - 스케일 아웃 시 Pod를 늘려서 실제 요청 처리

- 주요 구성 요소

  - 컨테이너 런타임

    - Docker, containerd, CRI-O 등
    - “도커를 설치해야 함?” → 컨테이너를 실행할 수 있는 런타임이 필요하다고 이해하면 됨

  - kubelet

    - 각 노드에서 실행되는 에이전트
    - Control Plane(API Server)와 통신
    - 이 노드에서 어떤 Pod를 실행해야 하는지 전달받고 상태를 보고

  - kube-proxy

    - Service(가상 IP, DNS) → 실제 Pod IP로 트래픽을 라우팅
    - iptables 혹은 IPVS로 네트워크 룰 관리

### Pod

> Kubernetes에서 배포의 최소 단위

- 하나 이상의 컨테이너를 묶은 논리 단위

- 같은 Pod 안 컨테이너 특징

  - 같은 네트워크 네임스페이스 공유 (localhost 공유)
  - 같은 Volume 공유

- “컨테이너 개수를 조절”하는 것이 아니라, Pod 개수를 조절하는 개념

### Service

> Pod 집합에 대한 안정적인 네트워크 엔드포인트

- 특징

  - Pod는 생성/삭제/재시작될 때마다 IP가 바뀜
  - Service는 고정된 가상 IP(ClusterIP)와 DNS 이름을 제공
  - Service 뒤에 연결된 여러 Pod로 트래픽을 로드 밸런싱

- 대표 유형

  - ClusterIP

    - 클러스터 내부 통신용 기본 타입

  - NodePort

    - 각 노드의 특정 포트로 외부에서 접근 가능

  - LoadBalancer

    - 클라우드 로드밸런서와 연동해 외부 공개용 엔드포인트 제공

### Deployment

> 특정 Pod 템플릿을 기준으로 “몇 개를 유지할지, 어떻게 업데이트할지”를 정의하는 리소스

- 예시 개념

  - `replicas: 3` → 동일한 Pod 3개 유지
  - 롤링 업데이트, 롤백 전략 설정 가능

- 사용자는 Deployment를 생성하고, Kubernetes가 이에 맞게 Pod를 생성, 삭제, 재시작

### Control Plane

> 전체 클러스터를 관리하는 두뇌 역할

- API Server

  - Kubernetes API의 엔트리 포인트
  - `kubectl`, kubelet, Controller 등이 모두 API Server와 통신

- etcd

  - 클러스터 상태(리소스 스펙, 메타데이터)를 저장하는 키-값 저장소

- Scheduler

  - 새로 생성해야 할 Pod를 어떤 Worker Node에 올릴지 결정
  - 노드 리소스 사용량, 제약 조건, Affinity 등을 고려해 스케줄링

- Controller Manager

  - 여러 종류의 컨트롤러 집합
  - 예: Deployment Controller, ReplicaSet Controller, Node Controller 등
  - 원하는 상태(예: replicas=3)와 현재 상태를 비교해 맞지 않으면 Pod 생성/삭제 등 조치 수행

- Cloud Controller Manager

  - 클라우드 프로바이더 연동 담당
  - 로드 밸런서, 노드 등록, 디스크 볼륨 등 클라우드 의존 기능을 분리해 관리

## 스케일 업 vs 스케일 아웃

- 스케일 아웃(수평 확장)

  - Deployment의 replica 수를 늘려 Pod 개수를 증가시키는 방식
  - 예: 3개에서 10개로 증가
  - 동일한 애플리케이션 인스턴스를 여러 개 띄워 요청을 분산 처리
  - Kubernetes에서 일반적으로 말하는 “스케일링”이 주로 이 개념

- 스케일 업(수직 확장)

  - 기존 노드나 Pod에 더 많은 CPU, 메모리 리소스를 할당하는 방식
  - 노드 자체의 스펙 업그레이드
  - 또는 Pod 리소스 요청/제한 상향 조정

## 정리

- 단일 호스트에서의 컨테이너 운영

  - `docker run` + 수동 스크립트로는 컨테이너 수가 많아질수록 운영 난이도가 급격히 상승

- 특정 클라우드 벤더 종속형 서비스

  - AWS ECS 등만 사용하면 해당 벤더 API, 개념에 묶이는 구조
  - 멀티 클라우드, 온프레 이식성 측면에서 제약 발생

- Kubernetes

  - 멀티 노드 환경에서 컨테이너 배포, 스케일링, 롤링 업데이트, 복구, 서비스 디스커버리를 자동화하는 오케스트레이션 플랫폼
  - Cluster, Node, Pod, Service, Deployment, Control Plane이라는 개념으로 전체 구조를 추상화
  - “멀티 머신용 Docker Compose”라는 비유로 감을 잡을 수 있지만, 셀프힐링, 오토스케일링, 선언적 상태 관리까지 포함하는 더 큰 플랫폼으로 이해하는 것이 적절한 방향
